import cv2
import face_recognition
import os
import time
import datetime
from tqdm import tqdm
import numpy as np
import pickle


def enhance_image_quality(image):
    """
    ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒìœ¼ë¡œ ì–¼êµ´ ê°ì§€ìœ¨ ê°œì„ 
    1. íˆìŠ¤í† ê·¸ë¨ í‰í™œí™”ë¥¼ í†µí•´ ì´ë¯¸ì§€ì˜ ëª…ì•” ëŒ€ë¹„ë¥¼ ê°œì„ í•©ë‹ˆë‹¤.
    2. ìƒ¤í”„ë‹ í•„í„°ë¥¼ ì ìš©í•˜ì—¬ ì´ë¯¸ì§€ì˜ ì„ ëª…ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.
    """
    # 1. íˆìŠ¤í† ê·¸ë¨ í‰í™œí™” (LAB ìƒ‰ ê³µê°„ì—ì„œ L ì±„ë„ì— ì ìš©)
    lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)
    lab[:, :, 0] = cv2.equalizeHist(lab[:, :, 0])
    enhanced = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)

    # 2. ìƒ¤í”„ë‹ í•„í„° ì ìš© (ì´ë¯¸ì§€ ì„ ëª…ë„ í–¥ìƒ)
    # ì´ ì»¤ë„ì€ ì´ë¯¸ì§€ì˜ ê°€ì¥ìë¦¬ë¥¼ ê°•ì¡°í•˜ì—¬ ì„ ëª…í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤.
    kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])
    sharpened = cv2.filter2D(enhanced, -1, kernel)

    return sharpened


def augment_reference_image(image, face_location):
    """
    ê¸°ì¤€ ì´ë¯¸ì§€ì—ì„œ ë‹¤ì–‘í•œ ë³€í˜•(íšŒì „, ë°ê¸°, ë°˜ì „)ì„ ìƒì„±í•˜ì—¬
    ì–¼êµ´ ì¸ì‹ì˜ ê°•ê±´ì„±ì„ ë†’ì…ë‹ˆë‹¤.
    dlibì˜ ì–¼êµ´ ëœë“œë§ˆí¬ ê°ì§€ê°€ ì•ˆì •ì ìœ¼ë¡œ ì´ë£¨ì–´ì§€ë„ë¡ ì–¼êµ´ í¬ë¡­ ì‹œ ì•½ê°„ì˜ ë§ˆì§„ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
    """
    top, right, bottom, left = face_location

    # ì–¼êµ´ í¬ë¡­ ì‹œ ì—¬ìœ  ê³µê°„ ì¶”ê°€ (ëœë“œë§ˆí¬ ê°ì§€ì— ë„ì›€)
    margin = 20  # í”½ì…€ ë‹¨ìœ„ë¡œ ì—¬ìœ  ê³µê°„ ì¶”ê°€ (ìƒí•˜ì¢Œìš°ì— 20í”½ì…€ì”© ì¶”ê°€)
    y1 = max(0, top - margin)
    y2 = min(image.shape[0], bottom + margin)
    x1 = max(0, left - margin)
    x2 = min(image.shape[1], right + margin)

    face_crop = image[y1:y2, x1:x2]  # ë§ˆì§„ì´ ì ìš©ëœ ì–¼êµ´ ì˜ì—­ í¬ë¡­

    augmented_faces = []

    # 1. ì›ë³¸ í¬ë¡­ ì´ë¯¸ì§€
    augmented_faces.append(face_crop)

    # 2. ì¢Œìš° ë°˜ì „ (í”„ë¡œí•„ ëŒ€ì¹­ì„± í™œìš©, ì˜† ì–¼êµ´ ì¸ì‹ì— ë„ì›€)
    flipped = cv2.flip(face_crop, 1)  # 1ì€ ì¢Œìš° ë°˜ì „ì„ ì˜ë¯¸
    augmented_faces.append(flipped)

    # 3. ë°ê¸° ì¡°ì • (ë‹¤ì–‘í•œ ì¡°ëª… ì¡°ê±´ì— ëŒ€ì‘)
    # alphaëŠ” ëŒ€ë¹„, betaëŠ” ë°ê¸°ë¥¼ ì¡°ì ˆí•©ë‹ˆë‹¤.
    bright = cv2.convertScaleAbs(face_crop, alpha=1.2, beta=10)  # ë” ë°ê²Œ
    dark = cv2.convertScaleAbs(face_crop, alpha=0.8, beta=-10)  # ë” ì–´ë‘¡ê²Œ
    augmented_faces.extend([bright, dark])

    # 4. ì•½ê°„ì˜ íšŒì „ (-15ë„, +15ë„) (ì–¼êµ´ ê°ë„ ë³€í™”ì— ëŒ€ì‘)
    height, width = face_crop.shape[:2]
    center = (width // 2, height // 2)

    for angle in [-15, 15]:  # -15ë„ì™€ +15ë„ë¡œ ê°ê° íšŒì „
        matrix = cv2.getRotationMatrix2D(center, angle, 1.0)  # íšŒì „ ë³€í™˜ í–‰ë ¬ ìƒì„±
        # íšŒì „ ì‹œ ì´ë¯¸ì§€ ë°–ìœ¼ë¡œ ë‚˜ê°€ëŠ” ë¶€ë¶„ì„ ê²€ì€ìƒ‰(BORDER_CONSTANT) ëŒ€ì‹ 
        # ê°€ì¥ìë¦¬ í”½ì…€ì„ ë³µì œ(BORDER_REPLICATE)í•˜ì—¬ ì±„ì›ë‹ˆë‹¤.
        # ì´ëŠ” dlibì˜ ëœë“œë§ˆí¬ ê°ì§€ê¸°ê°€ ë” ì•ˆì •ì ìœ¼ë¡œ ì‘ë™í•˜ë„ë¡ ë•ìŠµë‹ˆë‹¤.
        rotated = cv2.warpAffine(face_crop, matrix, (width, height),
                                 borderMode=cv2.BORDER_REPLICATE)
        augmented_faces.append(rotated)

    return augmented_faces


def create_multiple_encodings_from_single_image(net, image_path):
    """
    ë‹¨ì¼ ê¸°ì¤€ ì´ë¯¸ì§€ì—ì„œ ì—¬ëŸ¬ ê°œì˜ ì¦ê°•ëœ ì–¼êµ´ ì¸ì½”ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤.
    ê³„ì‚°ëœ ì¸ì½”ë”©ì€ ìºì‹œ íŒŒì¼ë¡œ ì €ì¥í•˜ì—¬ ë‹¤ìŒ ì‹¤í–‰ ì‹œ ì¬ì‚¬ìš©í•¨ìœ¼ë¡œì¨
    ê¸´ ì²˜ë¦¬ ì‹œê°„ì„ ë‹¨ì¶•í•©ë‹ˆë‹¤.
    """
    # ì¸ì½”ë”© ì €ì¥ ê²½ë¡œ ë° íŒŒì¼ëª… ì„¤ì •
    cache_dir = "face_encodings_cache"  # ìºì‹œ íŒŒì¼ì„ ì €ì¥í•  í´ë”ëª…
    os.makedirs(cache_dir, exist_ok=True)  # í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±

    # ì´ë¯¸ì§€ íŒŒì¼ëª…ì„ ê¸°ë°˜ìœ¼ë¡œ ìºì‹œ íŒŒì¼ëª… ìƒì„± (í™•ì¥ì ì œê±°)
    # ì˜ˆ: "sample2.jpg" -> "sample2_augmented_encodings.pkl"
    cache_filename = os.path.splitext(os.path.basename(image_path))[
        0] + "_augmented_encodings.pkl"
    cache_path = os.path.join(cache_dir, cache_filename)

    # ìºì‹œ íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³ , ìˆë‹¤ë©´ ë¡œë“œí•˜ì—¬ ë°˜í™˜
    if os.path.exists(cache_path):
        print(f"[INFO] ìºì‹œëœ ì¸ì½”ë”© ë¡œë“œ ì¤‘: {cache_path}")
        try:
            with open(cache_path, 'rb') as f:
                encodings = pickle.load(f)
            print(f"[INFO] ìºì‹œ ë¡œë“œ ì™„ë£Œ. ì´ {len(encodings)}ê°œì˜ ì¸ì½”ë”©.")
            return encodings
        except Exception as e:
            # ìºì‹œ íŒŒì¼ì´ ì†ìƒë˜ì—ˆê±°ë‚˜ ë¡œë“œ ì‹¤íŒ¨ ì‹œ, ê²½ê³  ë©”ì‹œì§€ ì¶œë ¥ í›„ ë‹¤ì‹œ ê³„ì‚°
            print(f"[WARNING] ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}. ì¸ì½”ë”©ì„ ë‹¤ì‹œ ê³„ì‚°í•©ë‹ˆë‹¤.")
            # ì†ìƒëœ ìºì‹œ íŒŒì¼ì€ ì‚­ì œí•˜ì—¬ ë‹¤ìŒ ì‹¤í–‰ ì‹œ ë‹¤ì‹œ ìƒì„±ë˜ë„ë¡ í•¨
            os.remove(cache_path)

    # ìºì‹œ íŒŒì¼ì´ ì—†ê±°ë‚˜ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ìƒˆë¡œ ê³„ì‚°
    print(f"[INFO] ê¸°ì¤€ ì–¼êµ´ ë¡œë”© ë° ì¦ê°• ì¤‘: {image_path}")

    image = cv2.imread(image_path)
    if image is None:
        print("[ERROR] ì´ë¯¸ì§€ ë¡œë”© ì‹¤íŒ¨")
        return []

    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    enhanced_image = enhance_image_quality(rgb_image)

    # ê¸°ì¤€ ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ ê°ì§€ (OpenCV DNN ì‚¬ìš©)
    print("[INFO] ê¸°ì¤€ ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ ê°ì§€ ì¤‘ (OpenCV DNN ëª¨ë¸ ì‚¬ìš©)...")
    start_time_detection = time.time()  # ê°ì§€ ì‹œì‘ ì‹œê°„ ê¸°ë¡
    face_locations = detect_faces_opencv_dnn(
        net, enhanced_image, confidence_threshold=0.7)
    end_time_detection = time.time()  # ê°ì§€ ì¢…ë£Œ ì‹œê°„ ê¸°ë¡
    print(
        f"[INFO] ê¸°ì¤€ ì´ë¯¸ì§€ ì–¼êµ´ ê°ì§€ ì™„ë£Œ (ì†Œìš” ì‹œê°„: {end_time_detection - start_time_detection:.2f}ì´ˆ)")

    if not face_locations:
        print("âŒ ê¸°ì¤€ ì–¼êµ´ì—ì„œ ì–¼êµ´ì„ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì •í™•í•œ ê¸°ì¤€ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.")
        return []

    # ê°ì§€ëœ ì²« ë²ˆì§¸ ì–¼êµ´ì˜ ìœ„ì¹˜ ì‚¬ìš© (ë‹¨ì¼ ì¸ë¬¼ ê¸°ì¤€ìœ¼ë¡œ ê°€ì •)
    reference_face_location = face_locations[0]
    print(f"[INFO] ê¸°ì¤€ ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ 1ê°œ ê°ì§€ ì™„ë£Œ: {reference_face_location}")

    # ì´ë¯¸ì§€ ì¦ê°• (ì›ë³¸ ì–¼êµ´ ìœ„ì¹˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í¬ë¡­ ë° ë³€í˜•)
    augmented_faces = augment_reference_image(
        enhanced_image, reference_face_location)
    print(f"[INFO] ì´ {len(augmented_faces)}ê°œì˜ ì¦ê°• ì–¼êµ´ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ.")

    encodings = []
    # tqdmì„ ì‚¬ìš©í•˜ì—¬ ì¦ê°• ì–¼êµ´ ì¸ì½”ë”© ì§„í–‰ ìƒí™©ì„ ì‹œê°ì ìœ¼ë¡œ í‘œì‹œ
    for i, face_aug in enumerate(tqdm(augmented_faces, desc="âœ¨ ì¦ê°• ì–¼êµ´ ì¸ì½”ë”© ì¤‘")):
        try:
            # ì¦ê°•ëœ ì´ë¯¸ì§€(face_aug)ì—ì„œ ì–¼êµ´ì„ ë‹¤ì‹œ ì°¾ê³  ì¸ì½”ë”©ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
            # íšŒì „ ì‹œ ê²€ì€ ë°°ê²½ ëŒ€ì‹  BORDER_REPLICATEë¥¼ ì‚¬ìš©í•˜ì—¬ dlibì˜ ì•ˆì •ì„±ì„ ë†’ì˜€ìœ¼ë¯€ë¡œ,
            # ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ìŠ¤ìŠ¤ë¡œ ì–¼êµ´ì„ ì°¾ë„ë¡ í•˜ëŠ” ê²ƒì´ ê°€ì¥ ê°•ê±´í•œ ë°©ë²•ì…ë‹ˆë‹¤.

            h, w, _ = face_aug.shape
            face_aug_rgb = cv2.cvtColor(face_aug, cv2.COLOR_BGR2RGB)
            face_locations_for_aug = [(0, w, h, 0)]

            encs = face_recognition.face_encodings(
                face_aug_rgb,
                known_face_locations=face_locations_for_aug
            )

            if encs:  # ì¸ì½”ë”©ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆë‹¤ë©´
                encodings.append(encs[0])  # ì²« ë²ˆì§¸ ì¸ì½”ë”©ë§Œ ì‚¬ìš© (ì–¼êµ´ì´ í•˜ë‚˜ë¼ê³  ê°€ì •)
            else:
                # ì–¼êµ´ì„ ì°¾ì§€ ëª»í•˜ì—¬ ì¸ì½”ë”©ì´ ìƒì„±ë˜ì§€ ì•Šì€ ê²½ìš° ê²½ê³  ë©”ì‹œì§€ ì¶œë ¥
                print(
                    f"\n[WARNING] ì¦ê°• ì–¼êµ´ #{i+1} ì—ì„œ ì–¼êµ´ì„ ì°¾ì§€ ëª»í•˜ì—¬ ì¸ì½”ë”© ì‹¤íŒ¨ (ì¸ì½”ë”© ì—†ìŒ).")

        except Exception as e:
            # ì¸ì½”ë”© ì¤‘ ì˜ˆì™¸ ë°œìƒ ì‹œ ì˜¤ë¥˜ ë©”ì‹œì§€ ì¶œë ¥ ë° ë””ë²„ê·¸ ì •ë³´ ì œê³µ
            print(f"\n[ERROR] ì¦ê°• ì–¼êµ´ #{i+1} ì¸ì½”ë”© ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
            print(
                f"[DEBUG] í•´ë‹¹ ì´ë¯¸ì§€ shape: {face_aug.shape}, dtype: {face_aug.dtype}")
            # ë””ë²„ê¹…ì„ ìœ„í•´ ë¬¸ì œëœ ì´ë¯¸ì§€ ì €ì¥ (í•„ìš” ì‹œ ì£¼ì„ í•´ì œ)
            # cv2.imwrite(f"debug_augmented_face_{i+1}_error.jpg", cv2.cvtColor(face_aug, cv2.COLOR_RGB2BGR))

    print(f"[INFO] ì´ {len(encodings)}ê°œì˜ ì¸ì½”ë”© ìƒì„± ì™„ë£Œ")

    # ê³„ì‚°ëœ ì¸ì½”ë”©ì„ ìºì‹œ íŒŒì¼ë¡œ ì €ì¥
    if encodings:
        try:
            with open(cache_path, 'wb') as f:  # ë°”ì´ë„ˆë¦¬ ì“°ê¸° ëª¨ë“œ ('wb')
                pickle.dump(encodings, f)  # ì¸ì½”ë”© ë¦¬ìŠ¤íŠ¸ë¥¼ íŒŒì¼ì— ë¤í”„
            print(f"[INFO] ì¸ì½”ë”© ìºì‹œ ì €ì¥ ì™„ë£Œ: {cache_path}")
        except Exception as e:
            print(f"[ERROR] ì¸ì½”ë”© ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
    else:
        print("[WARNING] ìƒì„±ëœ ì¸ì½”ë”©ì´ ì—†ì–´ ìºì‹œ íŒŒì¼ì„ ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    return encodings


def iou(boxA, boxB):
    """
    IoU (Intersection over Union)ë¥¼ ê³„ì‚°í•˜ì—¬ ë‘ ê°œì˜ ë°”ìš´ë”© ë°•ìŠ¤(ì–¼êµ´ ìœ„ì¹˜)ê°€
    ì–¼ë§ˆë‚˜ ê²¹ì¹˜ëŠ”ì§€ ì¸¡ì •í•©ë‹ˆë‹¤. ì¤‘ë³µ ì–¼êµ´ ê°ì§€ ì œê±°ì— ì‚¬ìš©ë©ë‹ˆë‹¤.
    boxAì™€ boxBëŠ” (top, right, bottom, left) í˜•ì‹ì˜ íŠœí”Œì…ë‹ˆë‹¤.
    """
    # ê²¹ì¹˜ëŠ” ì˜ì—­ì˜ ì¢Œí‘œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    xA = max(boxA[3], boxB[3])  # ê²¹ì¹˜ëŠ” ì‚¬ê°í˜•ì˜ ì™¼ìª½ ìƒë‹¨ x ì¢Œí‘œ
    yA = max(boxA[0], boxB[0])  # ê²¹ì¹˜ëŠ” ì‚¬ê°í˜•ì˜ ì™¼ìª½ ìƒë‹¨ y ì¢Œí‘œ
    xB = min(boxA[1], boxB[1])  # ê²¹ì¹˜ëŠ” ì‚¬ê°í˜•ì˜ ì˜¤ë¥¸ìª½ í•˜ë‹¨ x ì¢Œí‘œ
    yB = min(boxA[2], boxB[2])  # ê²¹ì¹˜ëŠ” ì‚¬ê°í˜•ì˜ ì˜¤ë¥¸ìª½ í•˜ë‹¨ y ì¢Œí‘œ

    # ê²¹ì¹˜ëŠ” ì˜ì—­ì˜ ë„ˆë¹„ì™€ ë†’ì´ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    inter_width = xB - xA
    inter_height = yB - yA

    # ê²¹ì¹˜ëŠ” ì˜ì—­ì´ ì—†ìœ¼ë©´ (ë„ˆë¹„ ë˜ëŠ” ë†’ì´ê°€ 0 ì´í•˜) IoUëŠ” 0.0
    if inter_width <= 0 or inter_height <= 0:
        return 0.0

    # ê²¹ì¹˜ëŠ” ì˜ì—­ì˜ ë©´ì 
    inter_area = inter_width * inter_height

    # ê° ë°”ìš´ë”© ë°•ìŠ¤ì˜ ë©´ì ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    boxA_area = (boxA[1] - boxA[3]) * (boxA[2] - boxA[0])
    boxB_area = (boxB[1] - boxB[3]) * (boxB[2] - boxB[0])

    # IoUë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤: ê²¹ì¹˜ëŠ” ë©´ì  / (ë°•ìŠ¤ A ë©´ì  + ë°•ìŠ¤ B ë©´ì  - ê²¹ì¹˜ëŠ” ë©´ì )
    iou_val = inter_area / float(boxA_area + boxB_area - inter_area)
    return iou_val


def detect_faces_opencv_dnn(net, frame, confidence_threshold=0.5):
    """OpenCVì˜ DNN ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í”„ë ˆì„ì—ì„œ ì–¼êµ´ ìœ„ì¹˜ë¥¼ ê°ì§€í•©ë‹ˆë‹¤."""
    (h, w) = frame.shape[:2]
    # ëª¨ë¸ì´ ê¸°ëŒ€í•˜ëŠ” 300x300 í¬ê¸°ë¡œ ì´ë¯¸ì§€ ë³€í™˜ ë° ë¸”ë¡­ ìƒì„±
    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0,
                                 (300, 300), (104.0, 177.0, 123.0))

    net.setInput(blob)
    detections = net.forward()
    face_locations = []

    # ê°ì§€ ê²°ê³¼ ë°˜ë³µ
    for i in range(0, detections.shape[2]):
        confidence = detections[0, 0, i, 2]

        # ì‹ ë¢°ë„ê°€ ì„ê³„ê°’ë³´ë‹¤ ë†’ì€ ê²½ìš°ì—ë§Œ ì²˜ë¦¬
        if confidence > confidence_threshold:
            # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ ê³„ì‚°
            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])
            (startX, startY, endX, endY) = box.astype("int")

            # face_recognition ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì‚¬ìš©í•˜ëŠ” (top, right, bottom, left) í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            face_locations.append((startY, endX, endY, startX))

    return face_locations


def advanced_face_detection(net, frame):
    """
    OpenCVì˜ DNN ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í”„ë ˆì„ì—ì„œ ì–¼êµ´ì„ ê°ì§€í•˜ê³ ,
    face_recognitionì„ ì‚¬ìš©í•˜ì—¬ ì¸ì½”ë”©í•©ë‹ˆë‹¤.
    """
    # OpenCV DNNì„ ì‚¬ìš©í•˜ì—¬ ì–¼êµ´ ìœ„ì¹˜ ê°ì§€
    # BGR í”„ë ˆì„ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•´ë„ ë¬´ë°©í•©ë‹ˆë‹¤.
    face_locations = detect_faces_opencv_dnn(
        net, frame, confidence_threshold=0.7)

    # face_recognitionì€ RGB ì´ë¯¸ì§€ë¥¼ ê¸°ëŒ€í•˜ë¯€ë¡œ ì¸ì½”ë”© ì „ì— ë³€í™˜
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    # ê°ì§€ëœ ìœ„ì¹˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì–¼êµ´ ì¸ì½”ë”©
    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)

    return face_locations, face_encodings


def process_video_enhanced_single_ref(video_path, reference_img_path, interval=1, tolerance=0.55):
    """
    ë‹¨ì¼ ê¸°ì¤€ ì¸ë¬¼ ì´ë¯¸ì§€ì™€ ì˜ìƒ íŒŒì¼ì„ ë¹„êµí•˜ì—¬,
    ì˜ìƒ ë‚´ì—ì„œ ê¸°ì¤€ ì¸ë¬¼ê³¼ ì¼ì¹˜í•˜ëŠ” ì–¼êµ´ì„ ì°¾ì•„ ì €ì¥í•©ë‹ˆë‹¤.
    í–¥ìƒëœ ì–¼êµ´ ê°ì§€ ë° ì¤‘ë³µ ì €ì¥ ë°©ì§€ ë¡œì§ì„ í¬í•¨í•©ë‹ˆë‹¤.
    """

    # 0. OpenCV DNN ëª¨ë¸ ë¡œë“œ
    proto_path = "C:/mini/models/deploy.prototxt"
    model_path = "C:/mini/models/res10_300x300_ssd_iter_140000.caffemodel"
    print("[INFO] OpenCV DNN ì–¼êµ´ ê°ì§€ ëª¨ë¸ ë¡œë”© ì¤‘...")
    net = cv2.dnn.readNetFromCaffe(proto_path, model_path)
    print("[INFO] ëª¨ë¸ ë¡œë”© ì™„ë£Œ.")

    # 1. ê¸°ì¤€ ì–¼êµ´ì—ì„œ ë‹¤ì¤‘ ì¸ì½”ë”© ìƒì„± (ìºì‹± ê¸°ëŠ¥ í™œìš©)
    reference_encodings = create_multiple_encodings_from_single_image(
        net, reference_img_path)
    if not reference_encodings:
        print("[ERROR] ê¸°ì¤€ ì–¼êµ´ ì²˜ë¦¬ ì‹¤íŒ¨. í”„ë¡œê·¸ë¨ ì¢…ë£Œ.")
        return

    # 2. ì˜ìƒ ì—´ê¸°
    print(f"[INFO] ì˜ìƒ ë¡œë”© ì¤‘: {video_path}")
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():  # ì˜ìƒ íŒŒì¼ì´ ì œëŒ€ë¡œ ì—´ë¦¬ì§€ ì•Šìœ¼ë©´ ì˜¤ë¥˜ ë©”ì‹œì§€ ì¶œë ¥
        print("[ERROR] ì˜ìƒ ì—´ê¸° ì‹¤íŒ¨:", video_path)
        return

    fps = cap.get(cv2.CAP_PROP_FPS)  # ì˜ìƒì˜ ì´ˆë‹¹ í”„ë ˆì„ ìˆ˜(FPS) ê°€ì ¸ì˜¤ê¸°
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # ì˜ìƒì˜ ì´ í”„ë ˆì„ ìˆ˜ ê°€ì ¸ì˜¤ê¸°
    # ê²€ì‚¬í•  í”„ë ˆì„ ê°„ê²© (ì˜ˆ: 1ì´ˆì— í•œ ë²ˆ ê²€ì‚¬í•˜ë ¤ë©´ fps ë§Œí¼)
    frame_interval = int(fps * interval)

    # ì¤‘ë³µ ì €ì¥ ë°©ì§€ ë¡œì§: ìµœê·¼ ë§¤ì¹­ í”„ë ˆì„ê³¼ ì¿¨ë‹¤ìš´ í”„ë ˆì„ ìˆ˜ ì„¤ì •
    cooldown_frames = int(fps * 2)  # 2ì´ˆì— í•œ ë²ˆë§Œ ì €ì¥ (ë™ì¼ ì¸ë¬¼ ì¤‘ë³µ ì €ì¥ ë°©ì§€)
    recent_match_frame = -cooldown_frames  # ì´ˆê¸°ê°’ì„ ìŒìˆ˜ë¡œ ì„¤ì •í•˜ì—¬ ì²« ë§¤ì¹­ í—ˆìš©

    # ë§¤ì¹­ëœ ì–¼êµ´ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•  í´ë” ìƒì„±
    os.makedirs("matched_faces", exist_ok=True)

    frame_count = 0  # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ í”„ë ˆì„ ë²ˆí˜¸
    match_count = 0  # ë§¤ì¹­ëœ ì–¼êµ´ ìˆ˜

    # tqdmì„ ì‚¬ìš©í•˜ì—¬ ì „ì²´ ì˜ìƒ ì²˜ë¦¬ ì§„í–‰ ìƒí™© í‘œì‹œ
    progress = tqdm(total=total_frames, desc="ğŸ DNN ì˜ìƒ ë¶„ì„ ì¤‘", unit="frame")

    # ì˜ìƒ í”„ë ˆì„ë³„ë¡œ ì²˜ë¦¬
    while cap.isOpened():
        ret, frame = cap.read()  # í•œ í”„ë ˆì„ ì½ê¸°
        if not ret:  # í”„ë ˆì„ì„ ë” ì´ìƒ ì½ì„ ìˆ˜ ì—†ìœ¼ë©´ ë£¨í”„ ì¢…ë£Œ
            break

        # ì§€ì •ëœ ê°„ê²©ë§ˆë‹¤ í”„ë ˆì„ ê²€ì‚¬
        if frame_count % frame_interval == 0:
            # ê³ ê¸‰ ì–¼êµ´ ê°ì§€ ì ìš©
            face_locations, face_encodings = advanced_face_detection(
                net, frame)

            # í˜„ì¬ í”„ë ˆì„ì—ì„œ ê°ì§€ëœ ëª¨ë“  ì–¼êµ´ì— ëŒ€í•´ ë°˜ë³µ
            for encoding, (top, right, bottom, left) in zip(face_encodings, face_locations):
                # ëª¨ë“  ê¸°ì¤€ ì¸ì½”ë”©(ì¦ê°•ëœ ì¸ì½”ë”© í¬í•¨)ê³¼ í˜„ì¬ ê°ì§€ëœ ì–¼êµ´ ì¸ì½”ë”© ê°„ì˜ ê±°ë¦¬ ê³„ì‚°
                distances = face_recognition.face_distance(
                    reference_encodings, encoding)
                min_distance = min(distances)  # ê°€ì¥ ì§§ì€ ê±°ë¦¬ (ê°€ì¥ ìœ ì‚¬í•œ ì¸ì½”ë”©)
                best_match_idx = np.argmin(distances)  # ê°€ì¥ ìœ ì‚¬í•œ ê¸°ì¤€ ì¸ì½”ë”©ì˜ ì¸ë±ìŠ¤

                # ë§¤ì¹­ ê¸°ì¤€ ì¶©ì¡± (ê±°ë¦¬ ì„ê³„ê°’ toleranceë³´ë‹¤ ì‘ê³ , ì¿¨ë‹¤ìš´ ê¸°ê°„ì´ ì§€ë‚¬ëŠ”ì§€)
                if min_distance < tolerance and frame_count - recent_match_frame >= cooldown_frames:
                    recent_match_frame = frame_count  # ë§ˆì§€ë§‰ ë§¤ì¹­ í”„ë ˆì„ ì—…ë°ì´íŠ¸
                    time_position_sec = frame_count / fps  # í˜„ì¬ í”„ë ˆì„ì˜ ì‹œê°„(ì´ˆ) ê³„ì‚°
                    time_str = str(datetime.timedelta(  # ì‹œ:ë¶„:ì´ˆ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                        seconds=int(time_position_sec)))
                    print(f"\nâœ… ì–¼êµ´ ë§¤ì¹­ ì„±ê³µ: {time_str}")
                    print(
                        f"   ê±°ë¦¬: {min_distance:.4f} (ê¸°ì¤€ ë³€í˜• #{best_match_idx + 1})")

                    # ì–¼êµ´ ì˜ì—­ í™•ëŒ€í•´ì„œ ì €ì¥
                    # ë§¤ì¹­ëœ ì–¼êµ´ ì£¼ë³€ì— ì—¬ë°±ì„ ì¶”ê°€í•˜ì—¬ ì €ì¥ (ì–¼êµ´ ì „ì²´ê°€ ì˜ë¦¬ì§€ ì•Šë„ë¡)
                    margin = 50  # 50 í”½ì…€ ì—¬ë°±
                    y1 = max(0, top - margin)
                    y2 = min(frame.shape[0], bottom + margin)
                    x1 = max(0, left - margin)
                    x2 = min(frame.shape[1], right + margin)

                    face_crop_to_save = frame[y1:y2, x1:x2]  # ì–¼êµ´ ì˜ì—­ í¬ë¡­
                    # ì €ì¥í•  íŒŒì¼ëª… ìƒì„± (í”„ë ˆì„ ë²ˆí˜¸, ì‹œê°„, ê±°ë¦¬ í¬í•¨)
                    save_path = os.path.join("matched_faces",
                                             f"frame_{frame_count}_t{time_str.replace(':', '')}_d{min_distance:.3f}.jpg")
                    cv2.imwrite(save_path, face_crop_to_save)  # ì´ë¯¸ì§€ ì €ì¥
                    match_count += 1  # ë§¤ì¹­ëœ ì–¼êµ´ ìˆ˜ ì¦ê°€

                    # ë§¤ì¹­ ì„±ê³µ ì‹œ í•´ë‹¹ í”„ë ˆì„ ì „ì²´ë¥¼ ì €ì¥í•˜ê³  ì–¼êµ´ì— ì‚¬ê°í˜• ê·¸ë¦¬ê¸° (ì„ íƒì‚¬í•­)
                    full_frame_path = os.path.join("matched_faces",
                                                   f"full_frame_{frame_count}.jpg")
                    # ì›ë³¸ í”„ë ˆì„ì— ì–¼êµ´ ìœ„ì¹˜ í‘œì‹œ (ì´ˆë¡ìƒ‰ ì‚¬ê°í˜•)
                    cv2.rectangle(frame, (left - margin, top - margin),  # ë§ˆì§„ì´ ì ìš©ëœ ì¢Œí‘œë¡œ ì‚¬ê°í˜• ê·¸ë¦¬ê¸°
                                  (right + margin, bottom + margin), (0, 255, 0), 3)  # (B,G,R), ë‘ê»˜ 3
                    cv2.imwrite(full_frame_path, frame)  # ì „ì²´ í”„ë ˆì„ ì €ì¥
                    break  # í•´ë‹¹ í”„ë ˆì„ì—ì„œ ì–¼êµ´ ë§¤ì¹­ì´ ì„±ê³µí•˜ë©´ ë” ì´ìƒ ë‹¤ë¥¸ ì–¼êµ´ì„ ì°¾ì§€ ì•Šê³  ë‹¤ìŒ í”„ë ˆì„ìœ¼ë¡œ ì´ë™

        frame_count += 1  # ë‹¤ìŒ í”„ë ˆì„ìœ¼ë¡œ ì´ë™
        progress.update(1)  # tqdm ì§„í–‰ë¥  ì—…ë°ì´íŠ¸

    cap.release()  # ì˜ìƒ íŒŒì¼ í•´ì œ
    progress.close()  # tqdm ì§„í–‰ë¥  ë°” ë‹«ê¸°
    print(f"\n[ì™„ë£Œ] ì´ ë§¤ì¹­ëœ ì–¼êµ´: {match_count}ê°œ")
    print(f"ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: matched_faces/ í´ë”")


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ë¶„ì„í•  ì˜ìƒ íŒŒì¼ ê²½ë¡œ
    # video_path = "C:/mini/videos/2025-05-11_[[NC vs ë‘ì‚°]]_ë”ë¸”í—¤ë” 2ì°¨ì „.mp4"
    video_path = "C:/mini/downloads/20250512.mp4"  # ë‹¤ë¥¸ ì˜ìƒ í…ŒìŠ¤íŠ¸ ì‹œ ì£¼ì„ í•´ì œ

    # ê¸°ì¤€ ì¸ë¬¼ ì–¼êµ´ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
    reference_img_path = "C:/mini/sample2.jpg"

    # ì–¼êµ´ ì¸ì‹ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
    process_video_enhanced_single_ref(
        video_path=video_path,
        reference_img_path=reference_img_path,
        interval=0.5,  # 0.5ì´ˆ(ì•½ 15í”„ë ˆì„)ë§ˆë‹¤ ì˜ìƒ í”„ë ˆì„ ê²€ì‚¬ (ê°„ê²©ì„ ì¤„ì´ë©´ ë” ê¼¼ê¼¼íˆ ê²€ì‚¬í•˜ì§€ë§Œ ì†ë„ ì €í•˜)
        tolerance=0.55  # ì–¼êµ´ ìœ ì‚¬ë„ í—ˆìš©ì¹˜ (ë‚®ì„ìˆ˜ë¡ ë” ì—„ê²©, ë†’ì„ìˆ˜ë¡ ë” ê´€ëŒ€)
        # ì˜†ì–¼êµ´ì´ë‚˜ ë‹¤ì–‘í•œ ê°ë„/í‘œì •ì— ëŒ€ì‘í•˜ê¸° ìœ„í•´ 0.6ì—ì„œ ì•½ê°„ ë‚®ì¶¤ (ë” ì—„ê²©í•´ì§)
    )
